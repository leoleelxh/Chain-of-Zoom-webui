import os
import sys
import tempfile
import shutil
import gradio as gr
import torch
from PIL import Image
import subprocess
import glob
from pathlib import Path

class ChainOfZoomInterface:
    def __init__(self):
        """åˆå§‹åŒ–Chain-of-Zoomä¸­æ–‡ç•Œé¢"""
        self.temp_dir = None
        self.output_dir = None
        
    def setup_directories(self):
        """è®¾ç½®ä¸´æ—¶ç›®å½•"""
        if self.temp_dir:
            shutil.rmtree(self.temp_dir, ignore_errors=True)
        self.temp_dir = tempfile.mkdtemp(prefix="coz_")
        self.output_dir = os.path.join(self.temp_dir, "output")
        os.makedirs(self.output_dir, exist_ok=True)
        return self.temp_dir, self.output_dir
    
    def get_gpu_info(self):
        """è·å–GPUä¿¡æ¯"""
        if not torch.cuda.is_available():
            return "CUDAä¸å¯ç”¨"
        
        gpu_info = []
        for i in range(torch.cuda.device_count()):
            props = torch.cuda.get_device_properties(i)
            total_memory = props.total_memory / 1024**3
            gpu_info.append(f"GPU {i}: {props.name} ({total_memory:.1f}GB)")
        
        return "\n".join(gpu_info)
    
    def process_image(self, 
                     input_image,
                     rec_type="recursive_multiscale",
                     prompt_type="vlm", 
                     custom_prompt="",
                     rec_num=3,
                     upscale=4,
                     align_method="nofix",
                     process_size=384,
                     efficient_memory=True,
                     mixed_precision="fp16",
                     vae_tiled_size=192,
                     latent_tiled_size=80,
                     latent_tiled_overlap=24):
        """
        å¤„ç†å›¾åƒçš„ä¸»è¦å‡½æ•°
        """
        
        if input_image is None:
            return None, "âŒ è¯·å…ˆä¸Šä¼ å›¾åƒï¼", None
            
        try:
            # è®¾ç½®ç›®å½•
            temp_dir, output_dir = self.setup_directories()
            
            # ä¿å­˜è¾“å…¥å›¾åƒ
            input_path = os.path.join(temp_dir, "input.png")
            if isinstance(input_image, str):
                shutil.copy(input_image, input_path)
            else:
                input_image.save(input_path)
            
            # æ„å»ºå‘½ä»¤è¡Œå‚æ•°
            cmd = [
                "python", "inference_coz.py",
                "-i", input_path,
                "-o", output_dir,
                "--rec_type", rec_type,
                "--prompt_type", prompt_type,
                "--rec_num", str(rec_num),
                "--upscale", str(upscale),
                "--align_method", align_method,
                "--process_size", str(process_size),
                "--mixed_precision", mixed_precision,
                "--vae_decoder_tiled_size", str(vae_tiled_size),
                "--latent_tiled_size", str(latent_tiled_size),
                "--latent_tiled_overlap", str(latent_tiled_overlap),
                "--pretrained_model_name_or_path", "stabilityai/stable-diffusion-3-medium-diffusers"
            ]
            
            # æ·»åŠ å¯é€‰å‚æ•°
            if custom_prompt.strip():
                cmd.extend(["--prompt", custom_prompt.strip()])
                
            if efficient_memory:
                cmd.append("--efficient_memory")
            
            # æ·»åŠ æ¨¡å‹è·¯å¾„ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            model_paths = {
                "--lora_path": "ckpt/SR_LoRA/model_20001.pkl",
                "--vae_path": "ckpt/SR_VAE/vae_encoder_20001.pt", 
                "--ram_ft_path": "ckpt/DAPE/DAPE.pth",
                "--ram_path": "ckpt/RAM/ram_swin_large_14m.pth"
            }
            
            for arg, path in model_paths.items():
                if os.path.exists(path):
                    cmd.extend([arg, path])
            
            # æ‰§è¡Œæ¨ç†
            print(f"ğŸš€ æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=os.getcwd())
            
            if result.returncode != 0:
                error_msg = f"âŒ å¤„ç†å¤±è´¥!\n\nğŸ“‹ æ ‡å‡†è¾“å‡º:\n{result.stdout}\n\nğŸš¨ é”™è¯¯è¾“å‡º:\n{result.stderr}"
                return None, error_msg, None
            
            # æŸ¥æ‰¾è¾“å‡ºå›¾åƒ
            recursive_dir = os.path.join(output_dir, "recursive")
            if os.path.exists(recursive_dir):
                output_files = glob.glob(os.path.join(recursive_dir, "*.png"))
                if output_files:
                    final_output = output_files[0]
                    
                    # æŸ¥æ‰¾å„ä¸ªå°ºåº¦çš„å›¾åƒ
                    per_scale_dir = os.path.join(output_dir, "per-scale")
                    scale_images = []
                    if os.path.exists(per_scale_dir):
                        for i in range(rec_num + 1):
                            scale_dir = os.path.join(per_scale_dir, f"scale{i}")
                            if os.path.exists(scale_dir):
                                scale_files = glob.glob(os.path.join(scale_dir, "*.png"))
                                if scale_files:
                                    scale_images.append(scale_files[0])
                    
                    success_msg = f"âœ… å¤„ç†æˆåŠŸï¼ç”Ÿæˆäº† {rec_num + 1} ä¸ªå°ºåº¦çš„å›¾åƒã€‚\n\nğŸ¯ æœ€ç»ˆæ”¾å¤§å€æ•°: {upscale ** rec_num}x"
                    return final_output, success_msg, scale_images
            
            return None, "âŒ æœªæ‰¾åˆ°è¾“å‡ºå›¾åƒï¼Œè¯·æ£€æŸ¥å¤„ç†è¿‡ç¨‹", None
            
        except Exception as e:
            error_msg = f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
            return None, error_msg, None
    
    def create_interface(self):
        """åˆ›å»ºä¸­æ–‡Gradioç•Œé¢"""
        
        # è·å–GPUä¿¡æ¯
        gpu_info = self.get_gpu_info()
        
        with gr.Blocks(
            title="Chain-of-Zoom: æç«¯è¶…åˆ†è¾¨ç‡å¤„ç†å·¥å…·", 
            theme=gr.themes.Soft(),
            css="""
            .gpu-info { background: linear-gradient(45deg, #1e3c72, #2a5298); color: white; padding: 15px; border-radius: 10px; margin: 10px 0; }
            .memory-warning { background: linear-gradient(45deg, #ff6b6b, #ee5a24); color: white; padding: 10px; border-radius: 8px; margin: 5px 0; }
            .memory-tip { background: linear-gradient(45deg, #00b894, #00a085); color: white; padding: 10px; border-radius: 8px; margin: 5px 0; }
            .preset-btn { margin: 5px; }
            """
        ) as interface:
            
            gr.Markdown(f"""
            # ğŸ” Chain-of-Zoom: æç«¯è¶…åˆ†è¾¨ç‡å¤„ç†å·¥å…·
            
            ## ğŸ“Š å½“å‰GPUçŠ¶æ€
            <div class="gpu-info">
            {gpu_info}
            </div>
            
            ### ğŸ¯ ä½¿ç”¨è¯´æ˜
            1. **ä¸Šä¼ å›¾åƒ** - é€‰æ‹©è¦å¤„ç†çš„å›¾ç‰‡
            2. **é…ç½®å‚æ•°** - æ ¹æ®ä½ çš„GPUæ˜¾å­˜è°ƒæ•´è®¾ç½®
            3. **å¼€å§‹å¤„ç†** - ç‚¹å‡»å¤„ç†æŒ‰é’®ç”Ÿæˆé«˜åˆ†è¾¨ç‡å›¾åƒ
            4. **ä¸‹è½½ç»“æœ** - ä¿å­˜å¤„ç†åçš„å›¾åƒ
            
            <div class="memory-warning">
            âš ï¸ <strong>24GBæ˜¾å­˜ä¼˜åŒ–æç¤º</strong><br>
            â€¢ å»ºè®®ä½¿ç”¨"ä¿å®ˆæ¨¡å¼"é¢„è®¾é…ç½®<br>
            â€¢ å¦‚æœå‡ºç°æ˜¾å­˜ä¸è¶³ï¼Œè¯·ä½¿ç”¨"æåº¦ä¿å®ˆ"æ¨¡å¼<br>
            â€¢ å¤„ç†å¤§å›¾æ—¶åŠ¡å¿…é™ä½"å¤„ç†å°ºå¯¸"å‚æ•°
            </div>
            """)
            
            with gr.Row():
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ“¤ è¾“å…¥é…ç½®")
                    
                    # è¾“å…¥å›¾åƒ
                    input_image = gr.Image(
                        label="ğŸ“· è¾“å…¥å›¾åƒ",
                        type="pil",
                        height=300
                    )
                    
                    # åŸºæœ¬å‚æ•°
                    with gr.Group():
                        gr.Markdown("#### ğŸ”§ åŸºæœ¬å‚æ•°")
                        
                        rec_type = gr.Dropdown(
                            choices=[
                                ("æœ€è¿‘é‚»æ’å€¼ (æœ€å¿«)", "nearest"),
                                ("åŒä¸‰æ¬¡æ’å€¼ (å¿«é€Ÿ)", "bicubic"), 
                                ("å•æ­¥è¶…åˆ†è¾¨ç‡", "onestep"),
                                ("é€’å½’å¤„ç†", "recursive"),
                                ("å¤šå°ºåº¦é€’å½’ (æ¨è)", "recursive_multiscale")
                            ],
                            value="recursive_multiscale",
                            label="ğŸ”„ é€’å½’ç±»å‹",
                            info="é€‰æ‹©å›¾åƒå¤„ç†æ–¹æ³•ï¼Œå¤šå°ºåº¦é€’å½’æ•ˆæœæœ€å¥½ä½†è€—æ—¶æœ€é•¿"
                        )
                        
                        prompt_type = gr.Dropdown(
                            choices=[
                                ("æ— æç¤º (æœ€å¿«)", "null"),
                                ("DAPEæ¨¡å‹æç¤º", "dape"),
                                ("è§†è§‰è¯­è¨€æ¨¡å‹ (æ¨è)", "vlm")
                            ],
                            value="vlm", 
                            label="ğŸ’¬ æç¤ºç±»å‹",
                            info="VLMæç¤ºæ•ˆæœæœ€å¥½ä½†é€Ÿåº¦è¾ƒæ…¢"
                        )
                        
                        custom_prompt = gr.Textbox(
                            label="âœï¸ è‡ªå®šä¹‰æç¤ºè¯ (å¯é€‰)",
                            placeholder="è¾“å…¥é¢å¤–çš„æè¿°æ–‡æœ¬...",
                            lines=2,
                            info="æ·»åŠ æè¿°å¯ä»¥æ”¹å–„ç”Ÿæˆè´¨é‡"
                        )
                    
                    # æ˜¾å­˜ä¼˜åŒ–é¢„è®¾
                    with gr.Group():
                        gr.Markdown("""
                        #### ğŸ¯ æ˜¾å­˜ä¼˜åŒ–é¢„è®¾ (24GB GPUä¸“ç”¨)
                        <div class="memory-tip">
                        ğŸ’¡ <strong>å¿«é€Ÿé…ç½®å»ºè®®</strong><br>
                        â€¢ <strong>æåº¦ä¿å®ˆ</strong>: æœ€å®‰å…¨ï¼Œé€‚åˆå¤§å›¾æˆ–æ˜¾å­˜ç´§å¼ <br>
                        â€¢ <strong>ä¿å®ˆæ¨¡å¼</strong>: å¹³è¡¡æ€§èƒ½å’Œæ˜¾å­˜ä½¿ç”¨<br>
                        â€¢ <strong>å¹³è¡¡æ¨¡å¼</strong>: è¾ƒå¥½æ•ˆæœï¼Œéœ€è¦å……è¶³æ˜¾å­˜
                        </div>
                        """)
                        
                        def apply_ultra_conservative():
                            return (256, 2, 2, True, "fp16", 128, 64, 16)
                        
                        def apply_conservative():
                            return (384, 3, 3, True, "fp16", 160, 80, 24)
                        
                        def apply_balanced():
                            return (512, 4, 4, True, "fp16", 192, 96, 32)
                        
                        with gr.Row():
                            ultra_conservative_btn = gr.Button(
                                "ğŸ›¡ï¸ æåº¦ä¿å®ˆ", 
                                variant="secondary", 
                                size="sm",
                                elem_classes="preset-btn"
                            )
                            conservative_btn = gr.Button(
                                "âš–ï¸ ä¿å®ˆæ¨¡å¼", 
                                variant="primary", 
                                size="sm",
                                elem_classes="preset-btn"
                            )
                            balanced_btn = gr.Button(
                                "ğŸš€ å¹³è¡¡æ¨¡å¼", 
                                variant="secondary", 
                                size="sm",
                                elem_classes="preset-btn"
                            )
                    
                    # é«˜çº§å‚æ•°
                    with gr.Accordion("ğŸ”¬ é«˜çº§å‚æ•°è®¾ç½®", open=False):
                        gr.Markdown("""
                        <div class="memory-warning">
                        âš ï¸ <strong>æ˜¾å­˜ä½¿ç”¨è­¦å‘Š</strong><br>
                        è°ƒæ•´è¿™äº›å‚æ•°ä¼šç›´æ¥å½±å“æ˜¾å­˜ä½¿ç”¨é‡ï¼Œè¯·è°¨æ…ä¿®æ”¹ï¼
                        </div>
                        """)
                        
                        with gr.Row():
                            rec_num = gr.Slider(
                                minimum=1,
                                maximum=5,
                                value=3,
                                step=1,
                                label="ğŸ”¢ é€’å½’æ¬¡æ•°",
                                info="âš¡ å½±å“æœ€ç»ˆæ”¾å¤§å€æ•°å’Œæ˜¾å­˜ä½¿ç”¨"
                            )
                            
                            upscale = gr.Slider(
                                minimum=2,
                                maximum=6,
                                value=4,
                                step=1,
                                label="ğŸ“ˆ å•æ­¥æ”¾å¤§å€æ•°",
                                info="ğŸ¯ æ¯æ¬¡é€’å½’çš„æ”¾å¤§å€æ•°"
                            )
                        
                        process_size = gr.Slider(
                            minimum=256,
                            maximum=768,
                            value=384,
                            step=64,
                            label="ğŸ–¼ï¸ å¤„ç†å°ºå¯¸",
                            info="ğŸ”¥ æ˜¾å­˜ä½¿ç”¨æœ€å…³é”®å‚æ•°ï¼è¶Šå¤§è¶Šè€—æ˜¾å­˜"
                        )
                        
                        align_method = gr.Dropdown(
                            choices=[
                                ("æ— æ ¡æ­£", "nofix"),
                                ("å°æ³¢å˜æ¢æ ¡æ­£", "wavelet"),
                                ("AdaINæ ¡æ­£", "adain")
                            ],
                            value="nofix",
                            label="ğŸ¨ é¢œè‰²å¯¹é½æ–¹æ³•",
                            info="é¢œè‰²æ ¡æ­£æ–¹æ³•ï¼Œå½±å“æœ€ç»ˆæ•ˆæœ"
                        )
                        
                        with gr.Row():
                            efficient_memory = gr.Checkbox(
                                value=True,
                                label="ğŸ’¾ å†…å­˜ä¼˜åŒ–æ¨¡å¼",
                                info="ğŸ”’ 24GBæ˜¾å­˜å¼ºçƒˆå»ºè®®å¼€å¯ï¼"
                            )
                            
                            mixed_precision = gr.Dropdown(
                                choices=[("åŠç²¾åº¦ (æ¨è)", "fp16"), ("å…¨ç²¾åº¦", "fp32")],
                                value="fp16",
                                label="ğŸ›ï¸ æ•°å€¼ç²¾åº¦",
                                info="ğŸ’¡ fp16å¯èŠ‚çœçº¦50%æ˜¾å­˜"
                            )
                    
                    # å†…å­˜å¾®è°ƒå‚æ•°
                    with gr.Accordion("âš™ï¸ æ˜¾å­˜å¾®è°ƒå‚æ•° (ä¸“å®¶çº§)", open=False):
                        gr.Markdown("""
                        <div class="memory-warning">
                        ğŸš¨ <strong>ä¸“å®¶çº§è®¾ç½®</strong><br>
                        è¿™äº›å‚æ•°ç›´æ¥æ§åˆ¶æ˜¾å­˜åˆ†é…ï¼Œä¸å½“è®¾ç½®å¯èƒ½å¯¼è‡´æ˜¾å­˜æº¢å‡ºï¼
                        </div>
                        """)
                        
                        vae_tiled_size = gr.Slider(
                            minimum=128,
                            maximum=384,
                            value=192,
                            step=32,
                            label="ğŸ§© VAEåˆ†å—å¤§å°",
                            info="ğŸ”¥ è¶Šå°è¶Šçœæ˜¾å­˜ï¼Œä½†å¤„ç†è¶Šæ…¢"
                        )
                        
                        latent_tiled_size = gr.Slider(
                            minimum=64,
                            maximum=128,
                            value=80,
                            step=16,
                            label="ğŸ­ æ½œåœ¨ç©ºé—´åˆ†å—å¤§å°", 
                            info="ğŸ”¥ æ§åˆ¶Transformeræ˜¾å­˜ä½¿ç”¨"
                        )
                        
                        latent_tiled_overlap = gr.Slider(
                            minimum=16,
                            maximum=48,
                            value=24,
                            step=8,
                            label="ğŸ”— åˆ†å—é‡å å¤§å°",
                            info="âš–ï¸ å½±å“åˆ†å—è¾¹ç•Œè´¨é‡"
                        )
                        
                        gr.Markdown("""
                        <div class="memory-tip">
                        ğŸ’¡ <strong>å‚æ•°è°ƒä¼˜å»ºè®®</strong><br>
                        â€¢ æ˜¾å­˜ä¸è¶³æ—¶ï¼šé™ä½æ‰€æœ‰"åˆ†å—å¤§å°"å‚æ•°<br>
                        â€¢ å¤„ç†å¤ªæ…¢æ—¶ï¼šé€‚å½“å¢åŠ åˆ†å—å¤§å°<br>
                        â€¢ è´¨é‡ä¸ä½³æ—¶ï¼šå¢åŠ é‡å å¤§å°
                        </div>
                        """)
                    
                    # å¤„ç†æŒ‰é’®
                    process_btn = gr.Button(
                        "ğŸš€ å¼€å§‹å¤„ç†å›¾åƒ",
                        variant="primary",
                        size="lg"
                    )
                    
                    # ç»‘å®šé¢„è®¾æŒ‰é’®
                    ultra_conservative_btn.click(
                        fn=apply_ultra_conservative,
                        outputs=[process_size, rec_num, upscale, efficient_memory, mixed_precision, vae_tiled_size, latent_tiled_size, latent_tiled_overlap]
                    )
                    
                    conservative_btn.click(
                        fn=apply_conservative,
                        outputs=[process_size, rec_num, upscale, efficient_memory, mixed_precision, vae_tiled_size, latent_tiled_size, latent_tiled_overlap]
                    )
                    
                    balanced_btn.click(
                        fn=apply_balanced,
                        outputs=[process_size, rec_num, upscale, efficient_memory, mixed_precision, vae_tiled_size, latent_tiled_size, latent_tiled_overlap]
                    )
                
                with gr.Column(scale=1):
                    gr.Markdown("### ğŸ“¥ å¤„ç†ç»“æœ")
                    
                    # çŠ¶æ€ä¿¡æ¯
                    status_text = gr.Textbox(
                        label="ğŸ“Š å¤„ç†çŠ¶æ€",
                        interactive=False,
                        lines=6,
                        info="æ˜¾ç¤ºå¤„ç†è¿›åº¦å’Œç»“æœä¿¡æ¯"
                    )
                    
                    # æœ€ç»ˆç»“æœ
                    final_output = gr.Image(
                        label="ğŸ¨ æœ€ç»ˆç»“æœ (æ‰€æœ‰å°ºåº¦åˆå¹¶)",
                        type="filepath",
                        height=300
                    )
                    
                    # å„ä¸ªå°ºåº¦çš„å›¾åƒ
                    scale_gallery = gr.Gallery(
                        label="ğŸ” å„å°ºåº¦å•ç‹¬ç»“æœ",
                        show_label=True,
                        elem_id="gallery",
                        columns=2,
                        rows=2,
                        height="auto"
                    )
            
            # ç¤ºä¾‹å›¾åƒ
            with gr.Row():
                gr.Markdown("### ğŸ–¼ï¸ ç¤ºä¾‹å›¾åƒ")
                example_images = []
                samples_dir = "samples"
                if os.path.exists(samples_dir):
                    sample_files = glob.glob(os.path.join(samples_dir, "*.png"))[:3]
                    for sample_file in sample_files:
                        example_images.append([sample_file])
                
                if example_images:
                    gr.Examples(
                        examples=example_images,
                        inputs=[input_image],
                        label="ç‚¹å‡»åŠ è½½ç¤ºä¾‹å›¾åƒè¿›è¡Œæµ‹è¯•"
                    )
            
            # ä½¿ç”¨è¯´æ˜å’Œæ•…éšœæ’é™¤
            with gr.Accordion("ğŸ“– ä½¿ç”¨è¯´æ˜ä¸æ•…éšœæ’é™¤", open=False):
                gr.Markdown("""
                ### ğŸ¯ å‚æ•°è¯¦è§£
                
                **é€’å½’ç±»å‹è¯´æ˜:**
                - **æœ€è¿‘é‚»æ’å€¼**: æœ€å¿«é€Ÿåº¦ï¼Œè´¨é‡æœ€ä½ï¼Œé€‚åˆå¿«é€Ÿé¢„è§ˆ
                - **åŒä¸‰æ¬¡æ’å€¼**: å¿«é€Ÿå¤„ç†ï¼Œä¸­ç­‰è´¨é‡
                - **å•æ­¥è¶…åˆ†è¾¨ç‡**: ä¸€æ¬¡æ€§å¤„ç†ï¼Œé€Ÿåº¦è¾ƒå¿«
                - **é€’å½’å¤„ç†**: é€æ­¥æ”¾å¤§ï¼Œè´¨é‡è¾ƒå¥½
                - **å¤šå°ºåº¦é€’å½’**: æœ€ä½³è´¨é‡ï¼Œä½†è€—æ—¶æœ€é•¿ (æ¨è)
                
                **æç¤ºç±»å‹è¯´æ˜:**
                - **æ— æç¤º**: æœ€å¿«é€Ÿåº¦ï¼Œä¸ä½¿ç”¨æ–‡æœ¬å¼•å¯¼
                - **DAPEæ¨¡å‹**: ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ç”Ÿæˆæç¤º
                - **è§†è§‰è¯­è¨€æ¨¡å‹**: æœ€ä½³æ•ˆæœï¼Œä½†é€Ÿåº¦è¾ƒæ…¢ (æ¨è)
                
                ### ğŸ”¥ 24GBæ˜¾å­˜ä¼˜åŒ–ç­–ç•¥
                
                **å¦‚æœé‡åˆ°æ˜¾å­˜ä¸è¶³ (CUDA OOM):**
                1. ğŸ›¡ï¸ **ç«‹å³ä½¿ç”¨"æåº¦ä¿å®ˆ"é¢„è®¾**
                2. ğŸ“‰ **é™ä½å¤„ç†å°ºå¯¸** åˆ° 256 æˆ–æ›´ä½
                3. ğŸ§© **å‡å°VAEåˆ†å—å¤§å°** åˆ° 128
                4. ğŸ”¢ **å‡å°‘é€’å½’æ¬¡æ•°** åˆ° 2
                5. ğŸ’¾ **ç¡®ä¿å¼€å¯å†…å­˜ä¼˜åŒ–æ¨¡å¼**
                6. ğŸ›ï¸ **ä½¿ç”¨fp16ç²¾åº¦**
                
                **æ€§èƒ½ä¸æ˜¾å­˜æƒè¡¡:**
                - **å¤„ç†å°ºå¯¸**: æœ€å…³é”®å‚æ•°ï¼Œç›´æ¥å½±å“æ˜¾å­˜ä½¿ç”¨
                - **VAEåˆ†å—å¤§å°**: æ˜¾å­˜ä½¿ç”¨ç¬¬äºŒé‡è¦å‚æ•°
                - **é€’å½’æ¬¡æ•°**: å½±å“æ€»å¤„ç†æ—¶é—´å’Œæœ€ç»ˆæ”¾å¤§å€æ•°
                - **å†…å­˜ä¼˜åŒ–**: æ˜¾è‘—èŠ‚çœæ˜¾å­˜ï¼Œä½†ä¼šé™ä½é€Ÿåº¦
                
                **ä¸åŒåœºæ™¯æ¨èè®¾ç½®:**
                - **å¤§å›¾ (>1024px)**: æåº¦ä¿å®ˆæ¨¡å¼ + å¤„ç†å°ºå¯¸256
                - **ä¸­å›¾ (512-1024px)**: ä¿å®ˆæ¨¡å¼
                - **å°å›¾ (<512px)**: å¹³è¡¡æ¨¡å¼
                
                ### ğŸš¨ å¸¸è§é—®é¢˜è§£å†³
                
                **é—®é¢˜: å¤„ç†å¡ä½ä¸åŠ¨**
                - âœ… ä½¿ç”¨æåº¦ä¿å®ˆé¢„è®¾
                - âœ… æ£€æŸ¥GPUæ˜¯å¦è¢«å…¶ä»–ç¨‹åºå ç”¨
                - âœ… é‡å¯Pythonè¿›ç¨‹æ¸…ç†æ˜¾å­˜
                
                **é—®é¢˜: CUDAå†…å­˜æº¢å‡º**
                - âœ… é™ä½æ‰€æœ‰å°ºå¯¸å‚æ•°è‡³æœ€å°å€¼
                - âœ… ç¡®ä¿å¼€å¯å†…å­˜ä¼˜åŒ–æ¨¡å¼
                - âœ… ä½¿ç”¨fp16ç²¾åº¦
                - âœ… å‡å°‘é€’å½’æ¬¡æ•°åˆ°1-2
                
                **é—®é¢˜: å¤„ç†é€Ÿåº¦ææ…¢**
                - âœ… å…³é—­å†…å­˜ä¼˜åŒ–æ¨¡å¼ (å¦‚æœæ˜¾å­˜å……è¶³)
                - âœ… é€‚å½“å¢åŠ åˆ†å—å¤§å°
                - âœ… ä½¿ç”¨æ›´ç®€å•çš„é€’å½’ç±»å‹
                
                **é—®é¢˜: ç”Ÿæˆè´¨é‡ä¸ä½³**
                - âœ… å¢åŠ å¤„ç†å°ºå¯¸
                - âœ… ä½¿ç”¨VLMæç¤ºç±»å‹
                - âœ… å¢åŠ åˆ†å—é‡å å¤§å°
                - âœ… æ·»åŠ è‡ªå®šä¹‰æç¤ºè¯
                
                ### ğŸ“Š æ˜¾å­˜ä½¿ç”¨ä¼°ç®—
                
                **æåº¦ä¿å®ˆæ¨¡å¼**: ~8-12GB
                **ä¿å®ˆæ¨¡å¼**: ~12-18GB  
                **å¹³è¡¡æ¨¡å¼**: ~18-24GB
                
                <div class="memory-tip">
                ğŸ’¡ <strong>ä¸“ä¸šæç¤º</strong><br>
                å»ºè®®åœ¨å¤„ç†å‰è¿è¡Œ <code>python memory_optimizer.py</code> æ¸…ç†æ˜¾å­˜å¹¶è·å–ä¸ªæ€§åŒ–æ¨èè®¾ç½®ï¼
                </div>
                """)
            
            # ç»‘å®šå¤„ç†å‡½æ•°
            process_btn.click(
                fn=self.process_image,
                inputs=[
                    input_image, rec_type, prompt_type, custom_prompt,
                    rec_num, upscale, align_method, process_size,
                    efficient_memory, mixed_precision, vae_tiled_size,
                    latent_tiled_size, latent_tiled_overlap
                ],
                outputs=[final_output, status_text, scale_gallery]
            )
        
        return interface

def main():
    """ä¸»å‡½æ•°"""
    # æ£€æŸ¥ç³»ç»Ÿç¯å¢ƒ
    try:
        import torch
        print("ğŸ”§ Chain-of-Zoom ä¸­æ–‡ç•Œé¢å¯åŠ¨ä¸­...")
        print(f"ğŸ“¦ PyTorchç‰ˆæœ¬: {torch.__version__}")
        print(f"ğŸ”¥ CUDAå¯ç”¨: {torch.cuda.is_available()}")
        
        if torch.cuda.is_available():
            print(f"ğŸ® CUDAè®¾å¤‡æ•°é‡: {torch.cuda.device_count()}")
            for i in range(torch.cuda.device_count()):
                props = torch.cuda.get_device_properties(i)
                print(f"   GPU {i}: {props.name} ({props.total_memory // 1024**3}GB)")
        else:
            print("âš ï¸ è­¦å‘Š: CUDAä¸å¯ç”¨ï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ")
            
    except ImportError:
        print("âŒ è­¦å‘Š: PyTorchæœªæ‰¾åˆ°ï¼Œè¯·å…ˆå®‰è£…ä¾èµ–: pip install -r requirements.txt")
    
    # åˆ›å»ºå¹¶å¯åŠ¨ç•Œé¢
    print("ğŸš€ æ­£åœ¨å¯åŠ¨Gradioç•Œé¢...")
    print("ğŸŒ ç½‘ç»œé…ç½®:")
    print("   - æœ¬åœ°è®¿é—®: http://localhost:7861")
    print("   - WSLè®¿é—®: http://127.0.0.1:7861") 
    print("   - å¦‚æœæ— æ³•è®¿é—®ï¼Œè¯·å°è¯•ä»¥ä¸‹æ–¹æ³•:")
    print("     1. åœ¨Windows PowerShellä¸­è¿è¡Œ: netsh interface portproxy add v4tov4 listenport=7861 listenaddress=0.0.0.0 connectport=7861 connectaddress=127.0.0.1")
    print("     2. æˆ–è€…åœ¨WSLä¸­è¿è¡Œ: export DISPLAY=:0")
    print("     3. æ£€æŸ¥Windowsé˜²ç«å¢™è®¾ç½®")
    
    coz_interface = ChainOfZoomInterface()
    interface = coz_interface.create_interface()
    
    # å¯åŠ¨ç•Œé¢ - ä½¿ç”¨æ›´å…¼å®¹çš„é…ç½®
    try:
        interface.launch(
            server_name="127.0.0.1",    # ä½¿ç”¨localhostè€Œä¸æ˜¯0.0.0.0
            server_port=7861,           # ä½¿ç”¨ä¸åŒç«¯å£é¿å…å†²çª
            share=False,                # ä¸åˆ›å»ºå…¬å…±é“¾æ¥
            debug=True,                 # è°ƒè¯•æ¨¡å¼
            inbrowser=False,            # ä¸è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨
            prevent_thread_lock=False   # å…è®¸çº¿ç¨‹é”å®š
        )
    except Exception as e:
        print(f"âŒ å¯åŠ¨å¤±è´¥: {e}")
        print("ğŸ”„ å°è¯•å¤‡ç”¨é…ç½®...")
        # å¤‡ç”¨é…ç½®
        interface.launch(
            server_name="0.0.0.0",      # å…è®¸æ‰€æœ‰IPè®¿é—®
            server_port=7862,           # ä½¿ç”¨å¤‡ç”¨ç«¯å£
            share=False,
            debug=False
        )

if __name__ == "__main__":
    main() 