import os
import sys
import tempfile
import shutil
import gradio as gr
import torch
from PIL import Image
import subprocess
import glob
from pathlib import Path

class ChainOfZoomInterface:
    def __init__(self):
        """åˆå§‹åŒ–Chain-of-Zoomç•Œé¢"""
        self.temp_dir = None
        self.output_dir = None
        
    def setup_directories(self):
        """è®¾ç½®ä¸´æ—¶ç›®å½•"""
        if self.temp_dir:
            shutil.rmtree(self.temp_dir, ignore_errors=True)
        self.temp_dir = tempfile.mkdtemp(prefix="coz_")
        self.output_dir = os.path.join(self.temp_dir, "output")
        os.makedirs(self.output_dir, exist_ok=True)
        return self.temp_dir, self.output_dir
    
    def process_image(self, 
                     input_image,
                     rec_type="recursive_multiscale",
                     prompt_type="vlm", 
                     custom_prompt="",
                     rec_num=4,
                     upscale=4,
                     align_method="nofix",
                     process_size=512,
                     efficient_memory=True,
                     mixed_precision="fp16",
                     vae_tiled_size=224,
                     latent_tiled_size=96,
                     latent_tiled_overlap=32):
        """
        å¤„ç†å›¾åƒçš„ä¸»è¦å‡½æ•°
        
        å‚æ•°è¯´æ˜Žï¼š
        - input_image: è¾“å…¥å›¾åƒ
        - rec_type: é€’å½’ç±»åž‹ (nearest/bicubic/onestep/recursive/recursive_multiscale)
        - prompt_type: æç¤ºç±»åž‹ (null/dape/vlm)
        - custom_prompt: è‡ªå®šä¹‰æç¤ºæ–‡æœ¬
        - rec_num: é€’å½’æ¬¡æ•°
        - upscale: æ”¾å¤§å€æ•°
        - align_method: é¢œè‰²å¯¹é½æ–¹æ³• (wavelet/adain/nofix)
        - process_size: å¤„ç†å°ºå¯¸
        - efficient_memory: æ˜¯å¦ä½¿ç”¨å†…å­˜ä¼˜åŒ–
        - mixed_precision: æ··åˆç²¾åº¦ (fp16/fp32)
        - vae_tiled_size: VAEåˆ†å—å¤§å°
        - latent_tiled_size: æ½œåœ¨ç©ºé—´åˆ†å—å¤§å°
        - latent_tiled_overlap: æ½œåœ¨ç©ºé—´åˆ†å—é‡å 
        """
        
        if input_image is None:
            return None, "Please upload an image first!", None
            
        try:
            # è®¾ç½®ç›®å½•
            temp_dir, output_dir = self.setup_directories()
            
            # ä¿å­˜è¾“å…¥å›¾åƒ
            input_path = os.path.join(temp_dir, "input.png")
            if isinstance(input_image, str):
                # å¦‚æžœæ˜¯æ–‡ä»¶è·¯å¾„
                shutil.copy(input_image, input_path)
            else:
                # å¦‚æžœæ˜¯PILå›¾åƒ
                input_image.save(input_path)
            
            # æž„å»ºå‘½ä»¤è¡Œå‚æ•°
            cmd = [
                "python", "inference_coz.py",
                "-i", input_path,
                "-o", output_dir,
                "--rec_type", rec_type,
                "--prompt_type", prompt_type,
                "--rec_num", str(rec_num),
                "--upscale", str(upscale),
                "--align_method", align_method,
                "--process_size", str(process_size),
                "--mixed_precision", mixed_precision,
                "--vae_decoder_tiled_size", str(vae_tiled_size),
                "--latent_tiled_size", str(latent_tiled_size),
                "--latent_tiled_overlap", str(latent_tiled_overlap),
                "--pretrained_model_name_or_path", "stabilityai/stable-diffusion-3-medium-diffusers"
            ]
            
            # æ·»åŠ å¯é€‰å‚æ•°
            if custom_prompt.strip():
                cmd.extend(["--prompt", custom_prompt.strip()])
                
            if efficient_memory:
                cmd.append("--efficient_memory")
            
            # æ·»åŠ æ¨¡åž‹è·¯å¾„ï¼ˆå¦‚æžœå­˜åœ¨ï¼‰
            model_paths = {
                "--lora_path": "ckpt/SR_LoRA/model_20001.pkl",
                "--vae_path": "ckpt/SR_VAE/vae_encoder_20001.pt", 
                "--ram_ft_path": "ckpt/DAPE/DAPE.pth",
                "--ram_path": "ckpt/RAM/ram_swin_large_14m.pth"
            }
            
            for arg, path in model_paths.items():
                if os.path.exists(path):
                    cmd.extend([arg, path])
            
            # æ‰§è¡ŒæŽ¨ç†
            print(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=os.getcwd())
            
            if result.returncode != 0:
                error_msg = f"å¤„ç†å¤±è´¥!\næ ‡å‡†è¾“å‡º: {result.stdout}\né”™è¯¯è¾“å‡º: {result.stderr}"
                return None, error_msg, None
            
            # æŸ¥æ‰¾è¾“å‡ºå›¾åƒ
            recursive_dir = os.path.join(output_dir, "recursive")
            if os.path.exists(recursive_dir):
                output_files = glob.glob(os.path.join(recursive_dir, "*.png"))
                if output_files:
                    final_output = output_files[0]
                    
                    # æŸ¥æ‰¾å„ä¸ªå°ºåº¦çš„å›¾åƒ
                    per_scale_dir = os.path.join(output_dir, "per-scale")
                    scale_images = []
                    if os.path.exists(per_scale_dir):
                        for i in range(rec_num + 1):
                            scale_dir = os.path.join(per_scale_dir, f"scale{i}")
                            if os.path.exists(scale_dir):
                                scale_files = glob.glob(os.path.join(scale_dir, "*.png"))
                                if scale_files:
                                    scale_images.append(scale_files[0])
                    
                    success_msg = f"å¤„ç†æˆåŠŸ! ç”Ÿæˆäº† {rec_num + 1} ä¸ªå°ºåº¦çš„å›¾åƒã€‚"
                    return final_output, success_msg, scale_images
            
            return None, "æœªæ‰¾åˆ°è¾“å‡ºå›¾åƒ", None
            
        except Exception as e:
            error_msg = f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
            return None, error_msg, None
    
    def create_interface(self):
        """åˆ›å»ºGradioç•Œé¢"""
        
        with gr.Blocks(title="Chain-of-Zoom: Extreme Super-Resolution", theme=gr.themes.Soft()) as interface:
            
            gr.Markdown("""
            # ðŸ”Ž Chain-of-Zoom: Extreme Super-Resolution
            
            This tool performs extreme super-resolution using scale autoregression and preference alignment.
            Upload an image and configure the parameters to enhance its resolution through recursive zooming.
            
            ## How it works:
            1. **Upload** your input image
            2. **Configure** the processing parameters  
            3. **Process** to generate multiple resolution scales
            4. **Download** the enhanced results
            
            ### ðŸ’¡ Memory Optimization Tips for 24GB GPU:
            - Use **Efficient Memory Mode** for maximum memory savings
            - Reduce **Process Size** to 256-384 for large images
            - Lower **VAE Tiled Size** to 128-192 for extreme memory saving
            - Use **fp16** precision to halve memory usage
            """)
            
            with gr.Row():
                with gr.Column(scale=1):
                    gr.Markdown("### Input Configuration")
                    
                    # è¾“å…¥å›¾åƒ
                    input_image = gr.Image(
                        label="Input Image",
                        type="pil",
                        height=300
                    )
                    
                    # åŸºæœ¬å‚æ•°
                    with gr.Group():
                        gr.Markdown("#### Basic Parameters")
                        
                        rec_type = gr.Dropdown(
                            choices=["nearest", "bicubic", "onestep", "recursive", "recursive_multiscale"],
                            value="recursive_multiscale",
                            label="Recursion Type",
                            info="Type of inference method to use"
                        )
                        
                        prompt_type = gr.Dropdown(
                            choices=["null", "dape", "vlm"],
                            value="vlm", 
                            label="Prompt Type",
                            info="Type of prompt generation method"
                        )
                        
                        custom_prompt = gr.Textbox(
                            label="Custom Prompt (Optional)",
                            placeholder="Enter additional prompt text...",
                            lines=2
                        )
                    
                    # é«˜çº§å‚æ•°
                    with gr.Accordion("Advanced Parameters", open=False):
                        rec_num = gr.Slider(
                            minimum=1,
                            maximum=6,  # é™ä½Žæœ€å¤§å€¼ä»¥èŠ‚çœå†…å­˜
                            value=3,    # é™ä½Žé»˜è®¤å€¼
                            step=1,
                            label="Recursion Number",
                            info="Number of recursive zoom steps (lower = less memory)"
                        )
                        
                        upscale = gr.Slider(
                            minimum=2,
                            maximum=6,  # é™ä½Žæœ€å¤§å€¼
                            value=4,
                            step=1,
                            label="Upscale Factor",
                            info="Magnification factor for each step"
                        )
                        
                        align_method = gr.Dropdown(
                            choices=["nofix", "wavelet", "adain"],
                            value="nofix",
                            label="Color Alignment Method",
                            info="Method for color correction"
                        )
                        
                        process_size = gr.Slider(
                            minimum=256,
                            maximum=768,  # é™ä½Žæœ€å¤§å€¼
                            value=384,    # é™ä½Žé»˜è®¤å€¼ä»¥èŠ‚çœå†…å­˜
                            step=64,
                            label="Process Size",
                            info="Processing resolution (lower = less memory, faster)"
                        )
                        
                        efficient_memory = gr.Checkbox(
                            value=True,
                            label="Efficient Memory Mode",
                            info="Use memory optimization (STRONGLY RECOMMENDED for 24GB GPU)"
                        )
                        
                        mixed_precision = gr.Dropdown(
                            choices=["fp16", "fp32"],
                            value="fp16",
                            label="Mixed Precision",
                            info="fp16 saves ~50% memory"
                        )
                    
                    # å†…å­˜ä¼˜åŒ–å‚æ•°
                    with gr.Accordion("Memory Optimization (Advanced)", open=False):
                        gr.Markdown("#### ðŸ”§ Fine-tune memory usage for your 24GB GPU")
                        
                        vae_tiled_size = gr.Slider(
                            minimum=128,
                            maximum=512,
                            value=192,  # æ›´ä¿å®ˆçš„é»˜è®¤å€¼
                            step=32,
                            label="VAE Decoder Tiled Size",
                            info="Smaller = less memory, slower processing"
                        )
                        
                        latent_tiled_size = gr.Slider(
                            minimum=64,
                            maximum=128,
                            value=80,   # æ›´ä¿å®ˆçš„é»˜è®¤å€¼
                            step=16,
                            label="Latent Tiled Size", 
                            info="Smaller = less memory for transformer"
                        )
                        
                        latent_tiled_overlap = gr.Slider(
                            minimum=16,
                            maximum=64,
                            value=24,   # æ›´ä¿å®ˆçš„é»˜è®¤å€¼
                            step=8,
                            label="Latent Tiled Overlap",
                            info="Overlap between tiles (affects quality vs memory)"
                        )
                        
                        # é¢„è®¾é…ç½®
                        gr.Markdown("#### ðŸŽ¯ Quick Presets for 24GB GPU:")
                        
                        def apply_ultra_conservative():
                            return (256, 192, 2, 128, 64, 16, True, "fp16")
                        
                        def apply_conservative():
                            return (384, 224, 3, 160, 80, 24, True, "fp16")
                        
                        def apply_balanced():
                            return (512, 256, 4, 192, 96, 32, True, "fp16")
                        
                        with gr.Row():
                            ultra_conservative_btn = gr.Button("Ultra Conservative", variant="secondary", size="sm")
                            conservative_btn = gr.Button("Conservative", variant="secondary", size="sm")
                            balanced_btn = gr.Button("Balanced", variant="primary", size="sm")
                        
                        ultra_conservative_btn.click(
                            fn=apply_ultra_conservative,
                            outputs=[process_size, vae_tiled_size, rec_num, latent_tiled_size, latent_tiled_overlap, latent_tiled_overlap, efficient_memory, mixed_precision]
                        )
                        
                        conservative_btn.click(
                            fn=apply_conservative,
                            outputs=[process_size, vae_tiled_size, rec_num, latent_tiled_size, latent_tiled_overlap, latent_tiled_overlap, efficient_memory, mixed_precision]
                        )
                        
                        balanced_btn.click(
                            fn=apply_balanced,
                            outputs=[process_size, vae_tiled_size, rec_num, latent_tiled_size, latent_tiled_overlap, latent_tiled_overlap, efficient_memory, mixed_precision]
                        )
                    
                    # å¤„ç†æŒ‰é’®
                    process_btn = gr.Button(
                        "ðŸš€ Process Image",
                        variant="primary",
                        size="lg"
                    )
                
                with gr.Column(scale=1):
                    gr.Markdown("### Results")
                    
                    # çŠ¶æ€ä¿¡æ¯
                    status_text = gr.Textbox(
                        label="Status",
                        interactive=False,
                        lines=4
                    )
                    
                    # æœ€ç»ˆç»“æžœ
                    final_output = gr.Image(
                        label="Final Result (All Scales Combined)",
                        type="filepath",
                        height=300
                    )
                    
                    # å„ä¸ªå°ºåº¦çš„å›¾åƒ
                    scale_gallery = gr.Gallery(
                        label="Individual Scale Results",
                        show_label=True,
                        elem_id="gallery",
                        columns=2,
                        rows=2,
                        height="auto"
                    )
            
            # ç¤ºä¾‹å›¾åƒ
            with gr.Row():
                gr.Markdown("### Example Images")
                example_images = []
                samples_dir = "samples"
                if os.path.exists(samples_dir):
                    sample_files = glob.glob(os.path.join(samples_dir, "*.png"))[:3]
                    for sample_file in sample_files:
                        example_images.append([sample_file])
                
                if example_images:
                    gr.Examples(
                        examples=example_images,
                        inputs=[input_image],
                        label="Click to load example images"
                    )
            
            # ä½¿ç”¨è¯´æ˜Ž
            with gr.Accordion("Usage Instructions & Troubleshooting", open=False):
                gr.Markdown("""
                ### Parameter Explanations:
                
                **Recursion Type:**
                - `nearest/bicubic`: Simple interpolation methods (fastest, lowest quality)
                - `onestep`: Single-step super-resolution  
                - `recursive`: Recursive processing with single-scale prompts
                - `recursive_multiscale`: Recursive processing with multi-scale aware prompts (recommended)
                
                **Prompt Type:**
                - `null`: No text prompts (fastest)
                - `dape`: Use DAPE model for prompt generation
                - `vlm`: Use Vision Language Model for prompt generation (recommended but slower)
                
                ### Memory Optimization for 24GB GPU:
                
                **If you get CUDA out of memory errors:**
                1. **Use Ultra Conservative preset** - safest option
                2. **Reduce Process Size** to 256 or lower
                3. **Lower VAE Tiled Size** to 128
                4. **Reduce Recursion Number** to 2-3
                5. **Use fp16 precision** (default)
                6. **Enable Efficient Memory Mode** (default)
                
                **Performance vs Memory Trade-offs:**
                - **Smaller Process Size**: Faster, less memory, lower quality
                - **Smaller VAE Tiled Size**: Much less memory, slower processing
                - **Fewer Recursion Steps**: Less total magnification, faster
                - **Efficient Memory**: Significant memory savings, slower processing
                
                **Recommended Settings for Different Scenarios:**
                - **Large images (>1024px)**: Ultra Conservative preset
                - **Medium images (512-1024px)**: Conservative preset  
                - **Small images (<512px)**: Balanced preset
                
                ### Troubleshooting:
                - **Process hangs**: Try Ultra Conservative preset
                - **CUDA OOM**: Reduce all size parameters by 50%
                - **Very slow**: Disable Efficient Memory if you have enough VRAM
                - **Poor quality**: Increase Process Size and VAE Tiled Size
                """)
            
            # ç»‘å®šå¤„ç†å‡½æ•°
            process_btn.click(
                fn=self.process_image,
                inputs=[
                    input_image, rec_type, prompt_type, custom_prompt,
                    rec_num, upscale, align_method, process_size,
                    efficient_memory, mixed_precision, vae_tiled_size,
                    latent_tiled_size, latent_tiled_overlap
                ],
                outputs=[final_output, status_text, scale_gallery]
            )
        
        return interface

def main():
    """ä¸»å‡½æ•°"""
    # æ£€æŸ¥å¿…è¦çš„ä¾èµ–
    try:
        import torch
        print(f"PyTorch version: {torch.__version__}")
        print(f"CUDA available: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"CUDA devices: {torch.cuda.device_count()}")
            for i in range(torch.cuda.device_count()):
                props = torch.cuda.get_device_properties(i)
                print(f"GPU {i}: {props.name} ({props.total_memory // 1024**3}GB)")
    except ImportError:
        print("Warning: PyTorch not found. Please install requirements first.")
    
    # åˆ›å»ºç•Œé¢
    coz_interface = ChainOfZoomInterface()
    interface = coz_interface.create_interface()
    
    # å¯åŠ¨ç•Œé¢
    interface.launch(
        server_name="0.0.0.0",  # å…è®¸å¤–éƒ¨è®¿é—®
        server_port=7860,       # ç«¯å£
        share=False,            # ä¸åˆ›å»ºå…¬å…±é“¾æŽ¥
        debug=True              # è°ƒè¯•æ¨¡å¼
    )

if __name__ == "__main__":
    main() 